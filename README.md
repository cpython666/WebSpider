# WebSpider项目手册

## 模块说明
app：提供web服务，比如爬虫管理系统（暂未开始）
config：允许站点域名配置
logs：按日期日志存储
models：数据库映射，数据库操作的方法
test：一些测试文件（无用）
utils：一些工具函数，包含：
- 页面精简
- 链接提取
- 站点链接过滤
- 链接与文件名相互转化
- chromedriver获取页面函数
- 获取页面，保存页面

## 状态码说明

200：初步爬取页面成功状态码
201：清除css，js后
202：201保存后202（html字段由数据库转移到本地html文件）
404：错误页面
405：404重新selenium爬取后依然错误

## 主文件说明：
run_huxiu使用requests请求新闻页面，可以请求到新闻信息，但会导致动态加载的比如相关新闻推荐不能爬到，因此程序在链接表的链接都被访问后，程序便会停滞，
run_huxiu_add是使用selenium请求页面，所以可以请求到相关新闻推荐，但一个程序运行五十分钟左右会出现访问不到网站的情况
run_huxiu_error是对错误请求再次使用selenium请求
run_huxiu_person是根据用户id请求到文章链接存储数据库的函数,需要使用huxiu_id.txt文件，需要去重
其他站点同理
## 主流程说明：
从链接数据库取出一个未访问链接，访问获取页面源代码（根据add是否决定是requests还是selenium），
获取到页面后，判断是否请求成功，精简页面，保存页面，提取链接，过滤链接，存储链接
就这样一直循环

## 本版本代做事项：
扩大域名范围，
规范代码，域名，过滤链接等
随机下载页面保存本地供检验页面是否爬取正确

## 注意：
网页是存在pages集合的html字段中，运行models里的Test文件里的move...函数将html存在本地并且状态码从201改为202

## 如何运行？
分别运行run开头的文件，
现在完善的站点有huxiu，thepaper，souhu，
ifeng一半